{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2025-07-09T19:38:05.594525Z",
     "end_time": "2025-07-09T19:38:05.685427Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, activations"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1 残差块"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class Residual(tf.keras.Model):\n",
    "    def __init__(self, num_channels, use_1x1conv = False, strides = 1):\n",
    "        super(Residual,self).__init__()\n",
    "        self.conv1 = layers.Conv2D(num_channels,\n",
    "                                   kernel_size = 3,\n",
    "                                   padding = 'same',\n",
    "                                   strides = strides)\n",
    "\n",
    "        self.conv2 = layers.Conv2D(num_channels,\n",
    "                                   strides = 1,\n",
    "                                   kernel_size = 3,\n",
    "                                   padding = 'same')\n",
    "        if use_1x1conv:\n",
    "            self.conv3 = layers.Conv2D(num_channels,\n",
    "                                       kernel_size = 1,\n",
    "                                       strides = strides)\n",
    "        else:\n",
    "            self.conv3 = None\n",
    "\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "\n",
    "    # 正向传播\n",
    "    def call(self, x):\n",
    "        Y = activations.relu(self.bn1(self.conv1(x)))\n",
    "        Y = self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            x = self.conv3(x)\n",
    "        outputs = activations.relu(Y + x)\n",
    "\n",
    "        return outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-07-09T19:38:05.618948Z",
     "end_time": "2025-07-09T19:38:05.772195Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2 ResNet模型"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (1)定义残差模块\n",
    "- 第一个模块需做特殊处理"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class ResnetBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_channels, num_res, first_block = False):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        # 存储残差块\n",
    "        self.listLayers = []\n",
    "        # 遍历残差数目生成模块\n",
    "        for i in range(num_res):\n",
    "            if i == 0 and not first_block:\n",
    "                self.listLayers.append(Residual(num_channels, use_1x1conv= True, strides=2))\n",
    "            else:\n",
    "                self.listLayers.append(Residual(num_channels))\n",
    "    # 前向传播\n",
    "    def call(self, X):\n",
    "        for layer in self.listLayers:\n",
    "            X = layer(X)\n",
    "\n",
    "        return X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-07-09T19:38:05.638327Z",
     "end_time": "2025-07-09T19:38:05.775647Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (2)构建Resnet网络"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class Resnet(tf.keras.Model):\n",
    "    def __init__(self, num_blocks):\n",
    "        super(Resnet, self).__init__()\n",
    "        # 输入层\n",
    "        self.conv = layers.Conv2D(\n",
    "            filters = 64,\n",
    "            kernel_size = 7,\n",
    "            padding = 'same',\n",
    "            strides = 2\n",
    "        )\n",
    "        # BN层\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        # 激活层\n",
    "        self.relu = layers.Activation('relu')\n",
    "        # 池化\n",
    "        self.mp = layers.MaxPool2D(\n",
    "            pool_size = 3,\n",
    "            strides = 2,\n",
    "            padding = 'same'\n",
    "        )\n",
    "        # 残差模块\n",
    "        self.res_block1 = ResnetBlock(64, num_blocks[0], first_block=True)\n",
    "        self.res_block2 = ResnetBlock(128, num_blocks[1])\n",
    "        self.res_block3 = ResnetBlock(256, num_blocks[2])\n",
    "        self.res_block4 = ResnetBlock(512, num_blocks[3])\n",
    "        # GAP\n",
    "        self.gap = layers.GlobalAvgPool2D()\n",
    "        # 全连接层\n",
    "        self.fc = layers.Dense(10, activation = 'softmax') # 也可写成（units = 10, activation = tf.keras.activations.softmax）\n",
    "\n",
    "    # 定义前向传播过程\n",
    "    def call(self, x):\n",
    "        # 输入部分传输过程\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.mp(x)\n",
    "        # block\n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = self.res_block3(x)\n",
    "        x = self.res_block4(x)\n",
    "        # 输出部分的传输\n",
    "        x = self.gap(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-07-09T19:38:05.653094Z",
     "end_time": "2025-07-09T19:38:05.779668Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"resnet\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"resnet\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (\u001B[38;5;33mConv2D\u001B[0m)                 │ (\u001B[38;5;34m1\u001B[0m, \u001B[38;5;34m112\u001B[0m, \u001B[38;5;34m112\u001B[0m, \u001B[38;5;34m64\u001B[0m)      │         \u001B[38;5;34m3,200\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (\u001B[38;5;34m1\u001B[0m, \u001B[38;5;34m112\u001B[0m, \u001B[38;5;34m112\u001B[0m, \u001B[38;5;34m64\u001B[0m)      │           \u001B[38;5;34m256\u001B[0m │\n│ (\u001B[38;5;33mBatchNormalization\u001B[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation (\u001B[38;5;33mActivation\u001B[0m)         │ ?                      │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (\u001B[38;5;33mMaxPooling2D\u001B[0m)    │ ?                      │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ resnet_block (\u001B[38;5;33mResnetBlock\u001B[0m)      │ ?                      │       \u001B[38;5;34m148,736\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ resnet_block_1 (\u001B[38;5;33mResnetBlock\u001B[0m)    │ ?                      │       \u001B[38;5;34m526,976\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ resnet_block_2 (\u001B[38;5;33mResnetBlock\u001B[0m)    │ ?                      │     \u001B[38;5;34m2,102,528\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ resnet_block_3 (\u001B[38;5;33mResnetBlock\u001B[0m)    │ ?                      │     \u001B[38;5;34m8,399,360\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d        │ ?                      │             \u001B[38;5;34m0\u001B[0m │\n│ (\u001B[38;5;33mGlobalAveragePooling2D\u001B[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;34m1\u001B[0m, \u001B[38;5;34m10\u001B[0m)                │         \u001B[38;5;34m5,130\u001B[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,200</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ resnet_block (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResnetBlock</span>)      │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">148,736</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ resnet_block_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResnetBlock</span>)    │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">526,976</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ resnet_block_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResnetBlock</span>)    │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,102,528</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ resnet_block_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResnetBlock</span>)    │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,399,360</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d        │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m11,186,186\u001B[0m (42.67 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,186,186</span> (42.67 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m11,178,378\u001B[0m (42.64 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,178,378</span> (42.64 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m7,808\u001B[0m (30.50 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,808</span> (30.50 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 实例化\n",
    "mynet = Resnet([2, 2, 2, 2])\n",
    "x = tf.random.uniform((1, 224, 224, 1))\n",
    "y = mynet(x)\n",
    "mynet.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-07-09T19:38:05.663947Z",
     "end_time": "2025-07-09T19:38:07.858461Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3 手写数字识别\n",
    "## （1）数据读取"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-07-09T19:38:07.452913Z",
     "end_time": "2025-07-09T19:38:07.859488Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 28, 28, 1)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-07-09T19:43:36.539393Z",
     "end_time": "2025-07-09T19:43:36.572244Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(10000, 28, 28, 1)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-07-09T19:43:39.731647Z",
     "end_time": "2025-07-09T19:43:39.754113Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# N H W C\n",
    "train_images = np.reshape(train_images, (train_images.shape[0], train_images.shape[1], train_images.shape[2], 1))\n",
    "\n",
    "test_images = np.reshape(test_images, (test_images.shape[0], test_images.shape[1], test_images.shape[2], 1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-07-09T19:43:07.960455Z",
     "end_time": "2025-07-09T19:43:08.920919Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# 定义两个方法随机抽取部分样本演示\n",
    "\n",
    "def get_train(size):\n",
    "    index = np.random.randint(0, np.shape(train_images)[0], size)\n",
    "\n",
    "    resize_images = tf.image.resize_with_pad(train_images[index], 224, 224, )\n",
    "\n",
    "    return resize_images.numpy(), train_labels[index]\n",
    "\n",
    "def get_test(size):\n",
    "    index = np.random.randint(0, np.shape(test_images)[0], size)\n",
    "\n",
    "    resize_images = tf.image.resize_with_pad(test_images[index], 224, 224, )\n",
    "\n",
    "    return resize_images.numpy(), test_labels[index]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-07-09T19:45:11.841100Z",
     "end_time": "2025-07-09T19:45:11.872234Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# 获取训练样本和测试样本\n",
    "train_image, train_label = get_train(256)\n",
    "test_image, test_label = get_test(128)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-07-09T19:38:07.749402Z",
     "end_time": "2025-07-09T19:38:08.691072Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (2)模型编译"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# 指定优化器，损失函数和评价指标\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate = 0.01, momentum = 0.0)\n",
    "\n",
    "mynet.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-07-09T19:45:27.373395Z",
     "end_time": "2025-07-09T19:45:27.396613Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (3)模型训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling Conv2D.call().\n\n\u001B[1mValue passed to parameter 'input' has DataType uint8 not in list of allowed values: float16, bfloat16, float32, float64, int32\u001B[0m\n\nArguments received by Conv2D.call():\n  • inputs=tf.Tensor(shape=(128, 28, 28, 1), dtype=uint8)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[20]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# 模型训练：指定训练数据集，batchsize, epoch, 验证集\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m \u001B[43mmynet\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_images\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      3\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m128\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m        \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# 显示整个训练的log\u001B[39;49;00m\n\u001B[32m      7\u001B[39m \u001B[43m        \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0.2\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;66;03m# 验证集\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Software\\envs\\TYPC\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    119\u001B[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001B[32m    120\u001B[39m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[32m    121\u001B[39m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m122\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e.with_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    123\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    124\u001B[39m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 34\u001B[39m, in \u001B[36mResnet.call\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     32\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m     33\u001B[39m     \u001B[38;5;66;03m# 输入部分传输过程\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m34\u001B[39m     x = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     35\u001B[39m     x = \u001B[38;5;28mself\u001B[39m.bn(x)\n\u001B[32m     36\u001B[39m     x = \u001B[38;5;28mself\u001B[39m.relu(x)\n",
      "\u001B[31mTypeError\u001B[39m: Exception encountered when calling Conv2D.call().\n\n\u001B[1mValue passed to parameter 'input' has DataType uint8 not in list of allowed values: float16, bfloat16, float32, float64, int32\u001B[0m\n\nArguments received by Conv2D.call():\n  • inputs=tf.Tensor(shape=(128, 28, 28, 1), dtype=uint8)"
     ]
    }
   ],
   "source": [
    "# 模型训练：指定训练数据集，batchsize, epoch, 验证集\n",
    "mynet.fit(train_images,\n",
    "        train_labels,\n",
    "        batch_size = 128,\n",
    "        epochs = 3,\n",
    "        verbose = 1, # 显示整个训练的log\n",
    "        validation_split = 0.2) # 验证集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## (4)模型评估"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling Conv2D.call().\n\n\u001B[1mValue passed to parameter 'input' has DataType uint8 not in list of allowed values: float16, bfloat16, float32, float64, int32\u001B[0m\n\nArguments received by Conv2D.call():\n  • inputs=tf.Tensor(shape=(None, 28, 28, 1), dtype=uint8)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mmynet\u001B[49m\u001B[43m.\u001B[49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\Software\\envs\\TYPC\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    119\u001B[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001B[32m    120\u001B[39m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[32m    121\u001B[39m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m122\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e.with_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    123\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    124\u001B[39m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[7]\u001B[39m\u001B[32m, line 34\u001B[39m, in \u001B[36mResnet.call\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     32\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcall\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[32m     33\u001B[39m     \u001B[38;5;66;03m# 输入部分传输过程\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m34\u001B[39m     x = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     35\u001B[39m     x = \u001B[38;5;28mself\u001B[39m.bn(x)\n\u001B[32m     36\u001B[39m     x = \u001B[38;5;28mself\u001B[39m.relu(x)\n",
      "\u001B[31mTypeError\u001B[39m: Exception encountered when calling Conv2D.call().\n\n\u001B[1mValue passed to parameter 'input' has DataType uint8 not in list of allowed values: float16, bfloat16, float32, float64, int32\u001B[0m\n\nArguments received by Conv2D.call():\n  • inputs=tf.Tensor(shape=(None, 28, 28, 1), dtype=uint8)"
     ]
    }
   ],
   "source": [
    "mynet.evaluate(test_images, test_labels, verbose = 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
